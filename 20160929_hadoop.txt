2016-09-29
# edit by liu2lin600

Hadoop：

♦ 大数据：海量数据
    ▫ 数据分类：
        结构化：行数据，可存放关系型数据库中
        非结构化：文件，图片...
        半结构化：html, xml, json, ...自描述，将结构与数据本身存储在一起

    ▫ Google论文：
        2003年：The Google File System
        2004年：Mapreduce: Simplified Date Processing On Large Cluster 
        2006年：BigTable: A Distributed Stored System For Structure Data

    ▫ 开源大数据处理方案：
        Storm   Twitter                 流式处理(实时分析)
        S4      Yahoo                   流式处理
        Hadoop  Apache                  批处理(时间无法预测)
        Spark   UC Berkeley AMPLab      批处理
        Disco   Nokia                   批处理
        HPCC    LexisNexis              批处理

    ▫ hadoop组成：由以上3篇论文的实现
        GFS       --> HDFS
        MapReduce --> MapReduce（开发API、框架、运行时环境）
        BigTable  --> Hbase

            HDFS + Mapreduce == Hadoop

    ▫ map/reduce：
        (1) 向外扩展
        (2) 假设故障常见，自我完成数据冗余，并自我完成故障处理
        (3) 将程序移向数据
        (4) 顺序处理数据，并避免随机访问
        (5) 向程序员隐藏系统级别的细节
        (6) 实现平滑扩展

♦ Hadoop：
    基于java语言，hadoop.apache.org
        hadoop-2.6.2  jdk1.6+
        hadoop-2.7.0  jdk1.7+

    ▫ 核心组件：
        • HDFS：集群，设计适用于少量的大容量单文件的文件系统
            1. NameNode：名称节点
                (1) 存储文件的metadata，运行时所有数据都保存到内存，整个HDFS可存储的文件数受限于NameNode的内存大小
                (2) 一个Block在NameNode中对应一条记录（一般一个block占用150字节），如果是大量的小文件，会消耗大量内存。同时map task的数量是由splits来决定的，所以用MapReduce处理大量的小文件时，就会产生过多的map task，线程管理开销将会增加作业时间。处理大量小文件的速度远远小于处理同等大小的大文件的速度。因此Hadoop建议存储大文件
                (3) 数据会定时保存到本地磁盘，但不保存block的位置信息，而是由DataNode注册时上报和运行时维护（NameNode中与DataNode相关的信息并不保存到NameNode的文件系统中，而是NameNode每次重启后，动态重建）
                (4) NameNode失效则整个HDFS都失效了，所以要保证NameNode的可用性

            2. Second NameNode：第二名称节点
                定时与NameNode进行同步（定期合并文件系统镜像和编辑日志，然后把合并后的传给NameNode，替换其镜像，并清空编辑日志，类似于CheckPoint机制），但NameNode失效后仍需要手工将其设置成主机

            3. DataNode：数据节点
                (1) 保存具体的block数据
                (2) 负责数据的读写操作和复制操作
                (3) DataNode启动时会向NameNode报告当前存储的数据块信息，后续也会定时报告修改信息
                (4) DataNode之间会进行通信，复制数据块，保证数据的冗余性

            4. Block：数据块
                (1) 基本存储单位，一般大小为64M
                (2) 一个大文件会被拆分成一个个的块，然后存储于不同的机器
                (3) 基本的读写单位，类似于磁盘的页，每次都是读写一个块
                (4) 每个块都会被复制到多台机器，默认复制3份

            5. HDFS Client：
                利用Hadoop API从NameNode上获取数据位置信息，再从指定DataNode中获取数据，存也一样过程

        • MapReduce：集群
            并行计算框架，它将运行与大规模集群上的复杂的并行计算过程高度地抽象为两个函数: Map和Reduce。一个Map/Reduce作业（Job）通常会把输入的数据集切分为若干独立的数据块，由Map任务（Task）以完全并行的方式处理它们，框架先对Map的输出进行排序，然后把结果输入给Reduce任务（Task）。作业的输入和输出都会被存储在文件系统中。 通常，MR框架和分布式文件系统是运行在一组相同的节点上的，也就是说，计算节点和存储节点在一起

            1. jobtracker(map+reduce)，追踪任务状态，一般运行在NameNode
            2. tasktracker，任务执行，一般运行在每个DataNode上

            执行过程：split -> map(mapper) -> shuffle and sort -> reducer -> store 
                split：(framework)将文件以指定的方式切割成键值对，用户自行开发程序完成
                map：将上述数据处理成reduce可折叠的键值对，所有map完成后统一下一步处理
                shuffle/sort：(framework)将键相同的发往同一个reducer
                reducer：折叠同一键的值
                store：(framework)可保存在HDFS上

                注：数据量较大时，有可能需要执行多次map/reduce

                补充过程：mapper --> combinder -> partitioner(shuffle and sort) --> reducer
                    combinder：在本地完成简单合并(merge)，由程序员自行开发
                    partitioner：负责sort后的键值发往reducer，由程序员自行开发

            发展：MRv1(Hadoop1) --> MRv2(Hadoop)
                MRv1：负责集群资源管理和数据处理
                MRv2：
                    YARN：负责集群资源管理
                    MRv2：数据处理
                        MR:  batch
                        Tez: execution engine

                        RM: Resource Manager
                        NM: Node Manager

                        AM: Application Master
                        container: mapreduce任务

    ▫ 相关组件：
        • HBase：Hadoop DataBase，集群方式存在
            基于Google Bigtable的分布式列存数据库，可运行在HDFS集群上，解决存储海量小文件，依赖zookeeper

            zookeeper：提供HBase与HDFS的等协调工作

        • Hive：
            建立在Hadoop上的数据仓库基础架构，提供一系统工具，用来进行数据提取、转化、加载，这是一种可以存储、查询和分析存储在Hadoop大规模数据的机制。Hive定义了简单地类SQL的查询语言，用户可以用SQL语法查询数据

        • Pig：
            脚本方式的Hadoop数据处理接口

        • flume、scribe、chukwa：
            日志收集工具

        • Sqoop、hiho：
            数据同步工具，用于传统数据库和Hadoop之间传递数据

        • Oozie：
            可扩展伸缩的工作流协调管理器

        • Spark：
            Spark是UC Berkeley AMP lab所开源的类Hadoop MapReduce的通用的并行计算框架，Spark基于map reduce算法实现的分布式计算，拥有Hadoop MapReduce所具有的优点；但不同于MapReduce的是Job中间输出和结果可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好地适用于数据挖掘与机器学习等需要迭代的map reduce的算法

            据说，Spark性能可以比Hadoop高100倍，而且它提供了更上层的API，同样地算法实现往往只有Hadoop的1/10甚至1/100的长度

        • Storm：
            实时数据分析处理

        • R Connectors：
            R语言实现，数据统计

        • Mahout：
            机器学习，分析行为，人工智能

    ▫ 主要发行版：
        Cloudera：CDH
        Hortonworks：HDP
        Intel：IDH
        MapR：

    ▫ 模型分类：
        • 单机模型：测试使用
        • 伪分布式模型：运行于单机
        • 分布式模型：群集模型

    ▫ hdfs命令操作

        <必要时需要切到hdfs用户>

        1. 语法：hadoop fs -CMD <args>

        • ls
            hadoop fs -ls [-R] /                # 列出hdfs根文件目录，-R递归

        • mkdir：创建目录
            hadoop fs -mkdir [-p] /tmp/xxx      # 创建目录 

        • put：上传
            hadoop fs -put <local-file> <hdfs-file>             # 上传文件或目录
            hadoop fs -moveFromLocal <local-file> <hdfs-file>
            hadoop fs -copyFromLocal <local-file> <hdfs-file>
        
        • get：下载
            hadoop fs -get <hdfs-file> [local-dir]              # 下载文件或目录
            hadoop fs -moveToLocal <hdfs-file> [local-dir]
            hadoop fs -copyToLocal <hdfs-file> [local-dir]

        • cp, rm, mv
            hadoop fs -cp <hdfs-file> <hdfs-file>
            hadoop fs -rm -r -skipTrash <hdfs-file>    # 直接删不入回站
            hadoop fs -mv 

        • du：查看大小
            hadoop fs -du < hdfs-path>
            hadoop fs -du -s <hdfs-path>
            hadoop fs -du -h <hdfs-path> 

        • stat：查看状态
            hadoop fs -stat /

        • fsck：健康状况
            hadoop fsck /

        • dfsadmin：dfs管理工具
            hadoop dfsadmin -report     # 报告各dn信息

        • text：将文本文件或某些格式的非文本文件通过文本格式输出
            hadoop fs -text <hdfs-file>

        • tail：显示文件末尾的1KB数据
            hadoop fs -tail <hdfs-file>

        • count：统计目录下的目录个数，文件个数，文件总计大小
            hadoop fs -count <hdfs-path>

        • getmerge：将hdfs指定目录下所有文件排序后合并到local指定的文件中，存在文件会覆盖
            hadoop fs -getmerge -nl  < hdfs dir >  < local file >

        • setrep：修改文件副本数
            hadoop fs -setrep -R 3 <hdfs-path>      # -R递归

        • test：检测文件或目录
            hadoop fs -test -e filename

                -e 检查文件是否存在。如果存在则返回0
                -z 检查文件是否是0字节。如果是则返回0 
                -d 如果路径是个目录，则返回1，否则返回0

        • balancer：手动均衡数据
            hdfs balancer

        2. job 相关 

        hadoop job -list                    # 查看 Job 信息
        hadoop job –kill job_id             # 杀死指定任务
        hadoop job -logs job_id             # 查看指定任务的日志
        hadoop job -history output-dir      # 指定路径下查看历史日志汇总
        hadoop job -history all output-dir  # 作业的更多细节
        hadoop job –status job_id           # 打印map和reduce完成百分比和所有计数器
        hadoop job -kill-task <task-id>     # 杀死任务。被杀死的任务不会不利于失败尝试
        hadoop job -fail-task <task-id>     # 使任务失败。被失败的任务会对失败尝试不利

Total jobs:1
                  JobId      State           StartTime      UserName           Queue      Priority       UsedContainers  RsvdContainers  UsedMem         RsvdMem         NeededMem         AM info
 job_1501040274955_1945    RUNNING       1502621183071    sa_cluster    root.sa_cluster     NORMAL                   11               0   11264M              0M            11264M      http://data01.shence.sa:8088/proxy/application_1501040274955_1945/


    ▫ yarn命令操作
        • application
            -list               ：从RM查看application列表
            -appStates <States> ：与-list一起，可取ALL, NEW, NEW_SAVING, SUBMITTED, ACCEPTED, RUNNING, FINISHED, FAILED, KILLED，可多个用逗号隔开
            -appTypes <Types>   ：与-list一起使用，基于传入的逗号分隔的application types列表过滤
            -kill <AppId>       ：杀死application
            -status <AppId>     ：打印指定application状态
                
                » yarn application -list
                » yarn application -list -appStates FAILED,NEW
                » yarn application -status job_1501040274955_1945

        • applicationattempt
            -list <AppId>           ：列出指定application的application attempts
            -status <Attempt Id>    ：打印application attempt的状态信息

                » yarn applicationattempt -list application_1491808105321_22924
                » yarn applicationattempt -status appattempt_1491808105321_22924_000001

        • container
            -list <Attempt Id>      ：列出application attempt的container列表
            -status <ContainerId>   ：打印container的状态

                » yarn container -list appattempt_1501040274955_1945_000001
                » yarn container -status container_1501040274955_1945_01_000002

        • logs
            yarn logs -applicationId <application ID> [options]
                
                » yarn logs -applicationId application_1491808105321_22924 [-appOwner hadoop]

        • node
            yarn node [options]

                » yarn node -list [-all]
                » yarn node -list -states NEW,RUNNING
                » yarn node -status <NodeId>

        • classpath：打印需要得到hadoop的jar和所需要的lib包路径
        • version：查看版本
        • queue
        • daemonlog
        • nodemanager
        • resourcemanager
        • rmadmin




















